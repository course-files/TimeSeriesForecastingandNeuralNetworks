{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Time Series Analysis, Time Series Forecasting, and Neural Networks"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides a comprehensive introduction to time series analysis and forecasting. We will cover the following topics:\n",
    "\n",
    "1.  **Stationarity in Time Series**\n",
    "    * What is Stationarity?\n",
    "    * Visual Indicators of Stationarity\n",
    "    * Statistical Tests of Stationarity (Augmented Dickey-Fuller Test)\n",
    "2.  **Forecasting Techniques**\n",
    "    * Exponential Smoothing (Simple, Double, and Triple)\n",
    "    * ARIMA\n",
    "    * SARIMA\n",
    "    * LSTM Neural Networks\n",
    "3.  **Model Comparison**\n",
    "4.  **Saving Predictions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Stationarity in Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Stationarity?\n",
    "\n",
    "A time series is said to be **stationary** if its statistical properties such as mean, variance, and autocorrelation are constant over time. Most time series models require the data to be stationary. If the time series is not stationary, we need to transform it to a stationary series before we can apply the models.\n",
    "\n",
    "A stationary time series has the following properties:\n",
    "\n",
    "* **Constant Mean:** The mean of the series is constant over time.\n",
    "* **Constant Variance:** The variance of the series is constant over time.\n",
    "* **Constant Autocorrelation:** The autocorrelation of the series is constant over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual Indicators of Stationarity\n",
    "\n",
    "We can visually inspect a time series plot to get an idea of whether it is stationary or not. Here are some visual cues:\n",
    "\n",
    "* The mean of the series should be constant. If there is a trend (upward or downward), the mean is not constant, and the series is not stationary.\n",
    "* The variance of the series should be constant. If the spread of the data changes over time, the variance is not constant, and the series is not stationary.\n",
    "* There should be no seasonal patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load our data and visualize it to check for stationarity."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# For suppressing warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the dataset\n",
    "# Make sure to upload your SP500Index.csv file to the Colab environment\n",
    "url = 'https://github.com/course-files/TimeSeriesForecastingandNeuralNetworks/raw/refs/heads/main/data/SP500Index.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Corrected the column name from 'Value' to 'SP500'\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df.set_index('Date', inplace=True)\n",
    "time_series = df['SP500']\n",
    "\n",
    "# Plot the time series\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_series)\n",
    "plt.title('Time Series Data')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('SP500')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Decomposing Time Series\n",
    "Decomposing a time series helps us understand its components: trend, seasonality, and residuals (or irregular component). This can provide insights into the underlying patterns in the data.\n",
    "We can use the `seasonal_decompose` function from `statsmodels` to decompose the time series. The decomposition can be either additive or multiplicative.\n",
    "- **Additive Decomposition:** The time series is expressed as the sum of its components: `Y(t) = Trend(t) + Seasonality(t) + Residual(t)`\n",
    "- **Multiplicative Decomposition:** The time series is expressed as the product of its components: `Y(t) = Trend(t) * Seasonality(t) * Residual(t)`\n",
    "- **Trend:** The long-term movement in the data.\n",
    "- **Seasonality:** The repeating short-term cycle in the data.\n",
    "- **Residual:** The random noise or irregular component in the data that cannot be explained by the trend or seasonality.\n",
    "- **Cycle:** A long-term oscillation in the data that is not necessarily seasonal. It can be thought of as a longer-term trend that fluctuates around a mean value.\n",
    "- **Note:** The cycle is often included in the residual if the decomposition is additive, as it captures long-term fluctuations that are not seasonal."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Decompose the time series (use model='additive' or 'multiplicative' as appropriate)\n",
    "decomposition = seasonal_decompose(time_series, model='multiplicative', period=12)\n",
    "\n",
    "# Plot the components\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.subplot(411)\n",
    "plt.plot(time_series, label='Original')\n",
    "plt.legend(loc='upper left')\n",
    "plt.subplot(412)\n",
    "plt.plot(decomposition.trend, label='Trend', color='orange')\n",
    "plt.legend(loc='upper left')\n",
    "plt.subplot(413)\n",
    "plt.plot(decomposition.seasonal, label='Seasonality', color='green')\n",
    "plt.legend(loc='upper left')\n",
    "plt.subplot(414)\n",
    "plt.plot(decomposition.resid, label='Irregular/Residual', color='red')\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Statistical Tests of Stationarity\n",
    "\n",
    "Visual inspection can be subjective. Therefore, we use statistical tests to check for stationarity. One of the most commonly used tests is the **Augmented Dickey-Fuller (ADF) test**.\n",
    "\n",
    "The ADF test is a statistical test that tests the null hypothesis that a unit root is present in a time series sample. The alternative hypothesis is that the time series is stationary.\n",
    "\n",
    "* **Null Hypothesis (H0):** The time series is non-stationary.\n",
    "* **Alternative Hypothesis (H1):** The time series is stationary.\n",
    "\n",
    "We interpret the result of the ADF test using the p-value. If the p-value is less than a significance level (e.g., 0.05), we reject the null hypothesis and conclude that the time series is stationary."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def adf_test(series):\n",
    "    \"\"\"Perform Augmented Dickey-Fuller test\"\"\"\n",
    "    result = adfuller(series, autolag='AIC')\n",
    "    print(f'ADF Statistic: {result[0]}')\n",
    "    print(f'p-value: {result[1]}')\n",
    "    for key, value in result[4].items():\n",
    "        print('Critial Values:')\n",
    "        print(f'   {key}, {value}')\n",
    "\n",
    "adf_test(time_series)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "If the p-value is greater than 0.05, we fail to reject the null hypothesis and conclude that the time series is non-stationary. In this case, we need to make the series stationary. A common way to do this is by **differencing** the series."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data Transformation (Stationarizing Techniques)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Differencing: Taking first differences `(X(t) - X(t-1))`"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# If the series is non-stationary, we can difference it\n",
    "time_series_diff = time_series.diff().dropna()\n",
    "\n",
    "# Plot the differenced series\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_series_diff)\n",
    "plt.title('Differenced Time Series Data')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('SP500')\n",
    "plt.show()\n",
    "\n",
    "# Perform ADF test on the differenced series\n",
    "adf_test(time_series_diff)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Detrending: Removing trend components"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Prepare the time index as a feature for regression\n",
    "time_index = np.arange(len(time_series)).reshape(-1, 1)\n",
    "\n",
    "# Fit linear regression (trend)\n",
    "lr = LinearRegression()\n",
    "lr.fit(time_index, time_series.values)\n",
    "trend = lr.predict(time_index)\n",
    "\n",
    "# Detrend the series\n",
    "detrended_series = time_series.values - trend\n",
    "\n",
    "# Plot the detrended series\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_series.index, detrended_series)\n",
    "plt.title('Detrended Time Series')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Detrended SP500')\n",
    "plt.show()\n",
    "\n",
    "adf_test(detrended_series)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Log transformation: For changing variance"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# Apply log transformation (add a small constant if data contains zeros)\n",
    "log_time_series = np.log(time_series + 1e-8)\n",
    "\n",
    "# Plot the log-transformed series\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_series.index, log_time_series)\n",
    "plt.title('Log-Transformed Time Series')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Log(SP500)')\n",
    "plt.show()\n",
    "\n",
    "adf_test(log_time_series)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Seasonal differencing: For seasonal patterns"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Seasonal differencing (e.g., period=12 for monthly data)\n",
    "seasonal_diff_log = log_time_series.diff(12).dropna()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(seasonal_diff_log)\n",
    "plt.title('Seasonally Differenced Log-Transformed Series')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Log(SP500) Seasonal Difference')\n",
    "plt.show()\n",
    "\n",
    "adf_test(seasonal_diff_log)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### In-Built Stationarizing Mechanism in Models\n",
    "1. **❌Exponential Smoothing (Simple, Double [Holt], and Triple [Holt-Winters])**\n",
    "- Exponential Smoothing techniques do not require the series to be stationary.\n",
    "- Instead, they explicitly model components such as trend and seasonality directly.\n",
    "- They handle non-stationarity by design, rather than transforming the data to a stationary form.\n",
    "\n",
    "2. **✅ARIMA (AutoRegressive Integrated Moving Average)**\n",
    "- ARIMA explicitly includes differencing (the \"I\" in ARIMA) as part of the model to make the series stationary.\n",
    "- You specify the `d` parameter in `ARIMA(p, d, q)`, where:\n",
    "  - `d = 1` tells the model to difference the data once. This step transforms a non-stationary series into a stationary one internally.\n",
    "\n",
    "3. **✅SARIMA (Seasonal ARIMA)**\n",
    "- SARIMA extends ARIMA with seasonal differencing.\n",
    "- It uses two differencing parameters:\n",
    "  - `d` for non-seasonal differencing,\n",
    "  - `D` for seasonal differencing over a defined period m.\n",
    "- Therefore, SARIMA also has built-in mechanisms to induce both stationarity and seasonal stationarity.\n",
    "\n",
    "4. **❌LSTM (Long Short-Term Memory Networks)**\n",
    "- LSTM models do not have explicit stationarizing mechanisms.\n",
    "- They learn directly from raw sequences, even if they are non-stationary.\n",
    "- However, data preprocessing such as normalization and differencing often improves performance.\n",
    "- LSTMs can model complex non-linear and non-stationary behavior, but they do not automatically make the data stationary."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Time Series Forecasting Techniques"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Exponential Smoothing\n",
    "\n",
    "Exponential smoothing is a time series forecasting method for univariate data. It is a weighted average of past observations, with the weights decaying exponentially as the observations get older.\n",
    "\n",
    "**Note:** Unlike ARIMA models, some exponential smoothing models are designed to handle non-stationary data directly by explicitly modeling trend and seasonality. This is why we can apply them to the original time series."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Simple Exponential Smoothing (SES)\n",
    "\n",
    "SES is suitable for time series data with no trend or seasonality."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_ses = SimpleExpSmoothing(time_series, initialization_method=\"estimated\").fit()\n",
    "predictions_ses = model_ses.forecast(60) # forecast for next 60 months\n",
    "\n",
    "future_index = pd.date_range(\n",
    "    start=time_series.index[-1] + pd.offsets.MonthEnd(1),\n",
    "    periods=60,\n",
    "    freq='M')\n",
    "predictions_ses = pd.Series(predictions_ses.values, index=future_index)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_series, label='Observed', alpha=0.7)\n",
    "plt.plot(predictions_ses, label='Simple Exponential Smoothing Forecast')\n",
    "plt.title('Simple Exponential Smoothing')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Double Exponential Smoothing (Holt's Method)\n",
    "\n",
    "Holt's method is an extension of SES that can handle time series data with a trend."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_holt = Holt(time_series, initialization_method=\"estimated\").fit()\n",
    "predictions_holt = model_holt.forecast(60)\n",
    "\n",
    "future_index = pd.date_range(\n",
    "    start=time_series.index[-1] + pd.offsets.MonthEnd(1),\n",
    "    periods=60,\n",
    "    freq='M')\n",
    "predictions_holt = pd.Series(predictions_holt.values, index=future_index)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_series, label='Observed', alpha=0.7)\n",
    "plt.plot(predictions_holt, label='Holt\\'s Forecast')\n",
    "plt.title('Double Exponential Smoothing (Holt\\'s Method)')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Triple Exponential Smoothing (Holt-Winters Method)\n",
    "\n",
    "The Holt-Winters method extends Holt's method to capture seasonality."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Assuming a seasonal period of 12 for monthly data. Change if your data has a different seasonal period.\n",
    "model_hw = ExponentialSmoothing(time_series, seasonal_periods=12, trend='add', seasonal='add', initialization_method=\"estimated\").fit()\n",
    "predictions_hw = model_hw.forecast(60)\n",
    "\n",
    "future_index = pd.date_range(\n",
    "    start=time_series.index[-1] + pd.offsets.MonthEnd(1),\n",
    "    periods=60,\n",
    "    freq='M')\n",
    "predictions_hw = pd.Series(predictions_holt.values, index=future_index)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_series, label='Observed')\n",
    "plt.plot(predictions_hw, label='Holt-Winters Forecast')\n",
    "plt.title('Triple Exponential Smoothing (Holt-Winters Method)')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### ARIMA\n",
    "\n",
    "ARIMA stands for AutoRegressive Integrated Moving Average. It is a class of models that explains a given time series based on its own past values, that is, its own lags and the lagged forecast errors.\n",
    "\n",
    "An ARIMA model is characterized by 3 parameters: (p, d, q).\n",
    "\n",
    "* **p:** The number of lag observations included in the model (lag order).\n",
    "* **d:** The number of times that the raw observations are differenced (degree of differencing).\n",
    "* **q:** The size of the moving average window (order of moving average).\n",
    "\n",
    "**Important Note:** You might wonder why we are using the original `time_series` which is non-stationary. The `statsmodels` implementation of ARIMA is smart. The `d` parameter in the `order=(p,d,q)` argument tells the model how many times to difference the data. So, the model takes care of the differencing internally. This is the standard and recommended way to use ARIMA models in `statsmodels`, as it simplifies the process and automatically returns the forecasts on the original scale."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Forecast the next 60 months using ARIMA\n",
    "model_arima = ARIMA(time_series, order=(1, 1, 1)).fit()\n",
    "predictions_arima = model_arima.forecast(steps=60)\n",
    "\n",
    "# Create a future index for the next 60 months\n",
    "future_index = pd.date_range(\n",
    "    start=time_series.index[-1] + pd.offsets.MonthEnd(1),\n",
    "    periods=60,\n",
    "    freq='M'\n",
    ")\n",
    "predictions_arima = pd.Series(predictions_arima.values, index=future_index)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_series, label='Observed')\n",
    "plt.plot(predictions_arima, label='ARIMA Forecast')\n",
    "plt.title('ARIMA Forecast (Next 60 Months)')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### SARIMA\n",
    "\n",
    "SARIMA (Seasonal ARIMA) is an extension of ARIMA that supports time series data with a seasonal component.\n",
    "\n",
    "A SARIMA model is characterized by 7 parameters: (p, d, q) x (P, D, Q, m).\n",
    "\n",
    "* **(p, d, q):** The non-seasonal parameters of the ARIMA model.\n",
    "* **(P, D, Q, m):** The seasonal parameters of the model, where 'm' is the number of time steps for a single seasonal period.\n",
    "\n",
    "Just like with ARIMA, we use the original time series here and let the model handle the differencing (both seasonal and non-seasonal) for us via the `d` and `D` parameters."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Forecast the next 60 months using SARIMA\n",
    "model_sarima = SARIMAX(time_series, order=(1, 1, 1), seasonal_order=(1, 1, 1, 12)).fit()\n",
    "predictions_sarima = model_sarima.forecast(steps=60)\n",
    "\n",
    "# Create a future index for the next 60 months\n",
    "future_index = pd.date_range(\n",
    "    start=time_series.index[-1] + pd.offsets.MonthEnd(1),\n",
    "    periods=60,\n",
    "    freq='M'\n",
    ")\n",
    "predictions_sarima = pd.Series(predictions_sarima.values, index=future_index)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_series, label='Observed')\n",
    "plt.plot(predictions_sarima, label='SARIMA Forecast')\n",
    "plt.title('SARIMA Forecast (Next 60 Months)')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Neural Network\n",
    "Long Short-Term Memory (LSTM) networks are a type of recurrent neural network (RNN) capable of learning long-term dependencies in sequence data. They are well suited for time series forecasting tasks because they can capture both short- and long-term temporal patterns.\n",
    "\n",
    "**Stationarity Requirement:** LSTM models do not strictly require the data to be stationary because they learn patterns directly from the raw sequences. However, it is recommended to scale the data and to remove strong trends or seasonality (for example, via differencing or decomposition) to improve convergence and predictive performance."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prepare data for LSTM\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_series = scaler.fit_transform(time_series.values.reshape(-1, 1))\n",
    "\n",
    "def create_sequences(data, window_size=12):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data[i:(i + window_size), 0])\n",
    "        y.append(data[i + window_size, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "window_size = 12\n",
    "X, y = create_sequences(scaled_series, window_size)\n",
    "train_size = len(X) - 12\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "model_lstm = Sequential([\n",
    "    LSTM(50, activation='tanh', input_shape=(window_size, 1)),\n",
    "    Dense(1)\n",
    "])\n",
    "model_lstm.compile(optimizer=Adam(learning_rate=0.01), loss='mse')\n",
    "\n",
    "history = model_lstm.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.1, verbose=0)\n",
    "\n",
    "# Forecast the next 60 months\n",
    "last_sequence = scaled_series[-window_size:].reshape(1, window_size, 1)\n",
    "future_predictions_scaled = []\n",
    "for _ in range(60):\n",
    "    next_pred = model_lstm.predict(last_sequence, verbose=0)\n",
    "    future_predictions_scaled.append(next_pred[0, 0])\n",
    "    last_sequence = np.concatenate(\n",
    "        [last_sequence[:, 1:, :], next_pred.reshape(1, 1, 1)],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "future_predictions = scaler.inverse_transform(np.array(future_predictions_scaled).reshape(-1, 1)).flatten()\n",
    "\n",
    "# Create future index for the next 60 months\n",
    "future_index = pd.date_range(\n",
    "    start=time_series.index[-1] + pd.offsets.MonthEnd(1),\n",
    "    periods=60,\n",
    "    freq='M'\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_series, label='Observed')\n",
    "plt.plot(future_index, future_predictions, label='LSTM Forecast (Next 60 Months)')\n",
    "plt.title('LSTM Forecast (Next 60 Months)')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Model Comparison"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Collecting Forecasts for Comparison"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# If you have actual values for the next 60 months, set them here:\n",
    "# true_values = actual_series_for_next_60_months\n",
    "\n",
    "# LSTM: use the 60-month forecast (future_predictions) and align index\n",
    "lstm_series = pd.Series(future_predictions, index=predictions_ses.index[:60])\n",
    "\n",
    "# Collect forecasts for 60 months\n",
    "forecasts_60 = {\n",
    "    'SES': predictions_ses[:60],\n",
    "    'Holt': predictions_holt[:60],\n",
    "    'Holt-Winters': predictions_hw[:60],\n",
    "    'ARIMA': predictions_arima[:60],\n",
    "    'SARIMA': predictions_sarima[:60],\n",
    "    'LSTM': lstm_series\n",
    "}\n",
    "\n",
    "# Optional: compute metrics if true future values are available\n",
    "def safe_mape(y_true, y_pred):\n",
    "    mask = y_true != 0\n",
    "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "\n",
    "# Uncomment and set true_values if you have them\n",
    "# metrics = []\n",
    "# for model_name, pred in forecasts_60.items():\n",
    "#     mae = mean_absolute_error(true_values, pred)\n",
    "#     rmse = np.sqrt(mean_squared_error(true_values, pred))\n",
    "#     mape = safe_mape(true_values.values, pred.values)\n",
    "#     metrics.append({'Model': model_name, 'MAE': mae, 'RMSE': rmse, 'MAPE': mape})\n",
    "# metrics_df = pd.DataFrame(metrics).set_index('Model')\n",
    "# print(\"Model Performance Comparison (60 months):\")\n",
    "# print(metrics_df.round(2))\n",
    "\n",
    "# Display forecasts for the next 60 months\n",
    "predictions_df_60 = pd.DataFrame(forecasts_60)\n",
    "display(predictions_df_60)\n",
    "\n",
    "# Plot all model forecasts for the next 60 months\n",
    "plt.figure(figsize=(14, 7))\n",
    "for model_name, pred in forecasts_60.items():\n",
    "    plt.plot(pred.index, pred.values, label=model_name)\n",
    "plt.title('60-Month Forecast Comparison')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('SP500 Forecast')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Optionally save to CSV\n",
    "# predictions_df_60.to_csv('./data/SP500Index_predictions_60months.csv')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Model Performance Comparison"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot MAE, RMSE, and MAPE for each model side by side\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "metrics_df['MAE'].plot(kind='bar', ax=axes[0], color='skyblue', title='MAE (Lower is Better)')\n",
    "axes[0].set_ylabel('MAE')\n",
    "axes[0].grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "metrics_df['RMSE'].plot(kind='bar', ax=axes[1], color='lightgreen', title='RMSE (Lower is Better)')\n",
    "axes[1].set_ylabel('RMSE')\n",
    "axes[1].grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "metrics_df['MAPE'].plot(kind='bar', ax=axes[2], color='salmon', title='MAPE % (Lower is Better)')\n",
    "axes[2].set_ylabel('MAPE (%)')\n",
    "axes[2].grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. Saving Predictions"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's see how to view and save our predictions to a CSV file."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"SES Predictions:\")\n",
    "print(predictions_ses)\n",
    "\n",
    "print(\"\\nHolt's Predictions:\")\n",
    "print(predictions_holt)\n",
    "\n",
    "print(\"\\nHolt-Winters Predictions:\")\n",
    "print(predictions_hw)\n",
    "\n",
    "print(\"\\nARIMA Predictions:\")\n",
    "print(predictions_arima)\n",
    "\n",
    "print(\"\\nSARIMA Predictions:\")\n",
    "print(predictions_sarima)\n",
    "\n",
    "print(\"\\nLSTM Predictions:\")\n",
    "# Convert predictions_lstm to Series with the same index as the last 12 true values\n",
    "lstm_series = pd.Series(predictions_lstm.flatten(), index=predictions_ses.index)\n",
    "print(lstm_series)\n",
    "\n",
    "# Save predictions to a CSV file\n",
    "predictions_df = pd.DataFrame({\n",
    "    'SES': predictions_ses,\n",
    "    'Holt': predictions_holt,\n",
    "    'Holt-Winters': predictions_hw,\n",
    "    'ARIMA': predictions_arima,\n",
    "    'SARIMA': predictions_sarima,\n",
    "    'LSTM': lstm_series\n",
    "})\n",
    "\n",
    "display(predictions_df)\n",
    "\n",
    "# predictions_df.to_csv('./data/SP500Index_predictions.csv')"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
