{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Time Series Analysis, Time Series Forecasting, and Neural Networks"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides a comprehensive introduction to time series analysis and forecasting. We will cover the following topics:\n",
    "\n",
    "1.  **Stationarity in Time Series**\n",
    "    * What is Stationarity?\n",
    "    * Visual Indicators of Stationarity\n",
    "    * Statistical Tests of Stationarity (Augmented Dickey-Fuller Test)\n",
    "2.  **Forecasting Techniques**\n",
    "    * Exponential Smoothing (Simple, Double, and Triple)\n",
    "    * ARIMA\n",
    "    * SARIMA\n",
    "    * LSTM Neural Networks\n",
    "3.  **Model Comparison**\n",
    "4.  **Saving Predictions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Stationarity in Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Stationarity?\n",
    "\n",
    "A time series is said to be **stationary** if its statistical properties such as mean, variance, and autocorrelation are constant over time. Most time series models require the data to be stationary. If the time series is not stationary, we need to transform it to a stationary series before we can apply the models.\n",
    "\n",
    "A stationary time series has the following properties:\n",
    "\n",
    "* **Constant Mean:** The mean of the series is constant over time.\n",
    "* **Constant Variance:** The variance of the series is constant over time.\n",
    "* **Constant Autocorrelation:** The autocorrelation of the series is constant over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual Indicators of Stationarity\n",
    "\n",
    "We can visually inspect a time series plot to get an idea of whether it is stationary or not. Here are some visual cues:\n",
    "\n",
    "* The mean of the series should be constant. If there is a trend (upward or downward), the mean is not constant, and the series is not stationary.\n",
    "* The variance of the series should be constant. If the spread of the data changes over time, the variance is not constant, and the series is not stationary.\n",
    "* There should be no seasonal patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load our data and visualize it to check for stationarity."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# Load the dataset\n",
    "# Make sure to upload your SP500Index.csv file to the Colab environment\n",
    "url = 'https://github.com/course-files/TimeSeriesForecastingandNeuralNetworks/raw/refs/heads/main/data/SP500Index.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Corrected the column name from 'Value' to 'SP500'\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df.set_index('Date', inplace=True)\n",
    "time_series = df['SP500']\n",
    "\n",
    "# Plot the time series\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_series)\n",
    "plt.title('Time Series Data')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('SP500')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Statistical Tests of Stationarity\n",
    "\n",
    "Visual inspection can be subjective. Therefore, we use statistical tests to check for stationarity. One of the most commonly used tests is the **Augmented Dickey-Fuller (ADF) test**.\n",
    "\n",
    "The ADF test is a statistical test that tests the null hypothesis that a unit root is present in a time series sample. The alternative hypothesis is that the time series is stationary.\n",
    "\n",
    "* **Null Hypothesis (H0):** The time series is non-stationary.\n",
    "* **Alternative Hypothesis (H1):** The time series is stationary.\n",
    "\n",
    "We interpret the result of the ADF test using the p-value. If the p-value is less than a significance level (e.g., 0.05), we reject the null hypothesis and conclude that the time series is stationary."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def adf_test(series):\n",
    "    \"\"\"Perform Augmented Dickey-Fuller test\"\"\"\n",
    "    result = adfuller(series, autolag='AIC')\n",
    "    print(f'ADF Statistic: {result[0]}')\n",
    "    print(f'p-value: {result[1]}')\n",
    "    for key, value in result[4].items():\n",
    "        print('Critial Values:')\n",
    "        print(f'   {key}, {value}')\n",
    "\n",
    "adf_test(time_series)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "If the p-value is greater than 0.05, we fail to reject the null hypothesis and conclude that the time series is non-stationary. In this case, we need to make the series stationary. A common way to do this is by **differencing** the series."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data Transformation"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Differencing: Taking first differences `(X(t) - X(t-1))`"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# If the series is non-stationary, we can difference it\n",
    "time_series_diff = time_series.diff().dropna()\n",
    "\n",
    "# Plot the differenced series\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_series_diff)\n",
    "plt.title('Differenced Time Series Data')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('SP500')\n",
    "plt.show()\n",
    "\n",
    "# Perform ADF test on the differenced series\n",
    "adf_test(time_series_diff)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Detrending: Removing trend components"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Prepare the time index as a feature for regression\n",
    "time_index = np.arange(len(time_series)).reshape(-1, 1)\n",
    "\n",
    "# Fit linear regression (trend)\n",
    "lr = LinearRegression()\n",
    "lr.fit(time_index, time_series.values)\n",
    "trend = lr.predict(time_index)\n",
    "\n",
    "# Detrend the series\n",
    "detrended_series = time_series.values - trend\n",
    "\n",
    "# Plot the detrended series\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_series.index, detrended_series)\n",
    "plt.title('Detrended Time Series')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Detrended SP500')\n",
    "plt.show()\n",
    "\n",
    "adf_test(detrended_series)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Log transformation: For changing variance"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# Apply log transformation (add a small constant if data contains zeros)\n",
    "log_time_series = np.log(time_series + 1e-8)\n",
    "\n",
    "# Plot the log-transformed series\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_series.index, log_time_series)\n",
    "plt.title('Log-Transformed Time Series')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Log(SP500)')\n",
    "plt.show()\n",
    "\n",
    "adf_test(log_time_series)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Seasonal differencing: For seasonal patterns"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Seasonal differencing (e.g., period=12 for monthly data)\n",
    "seasonal_diff_log = log_time_series.diff(12).dropna()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(seasonal_diff_log)\n",
    "plt.title('Seasonally Differenced Log-Transformed Series')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Log(SP500) Seasonal Difference')\n",
    "plt.show()\n",
    "\n",
    "adf_test(seasonal_diff_log)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Time Series Forecasting Techniques"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Exponential Smoothing\n",
    "\n",
    "Exponential smoothing is a time series forecasting method for univariate data. It is a weighted average of past observations, with the weights decaying exponentially as the observations get older.\n",
    "\n",
    "**Note:** Unlike ARIMA models, some exponential smoothing models are designed to handle non-stationary data directly by explicitly modeling trend and seasonality. This is why we can apply them to the original time series."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Simple Exponential Smoothing (SES)\n",
    "\n",
    "SES is suitable for time series data with no trend or seasonality."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_ses = SimpleExpSmoothing(time_series, initialization_method=\"estimated\").fit()\n",
    "predictions_ses = model_ses.forecast(12) # forecast for next 12 months\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_series, label='Observed')\n",
    "plt.plot(predictions_ses, label='SES Forecast')\n",
    "plt.title('Simple Exponential Smoothing')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Double Exponential Smoothing (Holt's Method)\n",
    "\n",
    "Holt's method is an extension of SES that can handle time series data with a trend."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_holt = Holt(time_series, initialization_method=\"estimated\").fit()\n",
    "predictions_holt = model_holt.forecast(12)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_series, label='Observed')\n",
    "plt.plot(predictions_holt, label='Holt\\'s Forecast')\n",
    "plt.title('Double Exponential Smoothing (Holt\\'s Method)')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Triple Exponential Smoothing (Holt-Winters Method)\n",
    "\n",
    "The Holt-Winters method extends Holt's method to capture seasonality."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Assuming a seasonal period of 12 for monthly data. Change if your data has a different seasonal period.\n",
    "model_hw = ExponentialSmoothing(time_series, seasonal_periods=12, trend='add', seasonal='add', initialization_method=\"estimated\").fit()\n",
    "predictions_hw = model_hw.forecast(12)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_series, label='Observed')\n",
    "plt.plot(predictions_hw, label='Holt-Winters Forecast')\n",
    "plt.title('Triple Exponential Smoothing (Holt-Winters Method)')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### ARIMA\n",
    "\n",
    "ARIMA stands for AutoRegressive Integrated Moving Average. It is a class of models that explains a given time series based on its own past values, that is, its own lags and the lagged forecast errors.\n",
    "\n",
    "An ARIMA model is characterized by 3 parameters: (p, d, q).\n",
    "\n",
    "* **p:** The number of lag observations included in the model (lag order).\n",
    "* **d:** The number of times that the raw observations are differenced (degree of differencing).\n",
    "* **q:** The size of the moving average window (order of moving average).\n",
    "\n",
    "**Important Note:** You might wonder why we are using the original `time_series` which is non-stationary. The `statsmodels` implementation of ARIMA is smart. The `d` parameter in the `order=(p,d,q)` argument tells the model how many times to difference the data. So, the model takes care of the differencing internally. This is the standard and recommended way to use ARIMA models in `statsmodels`, as it simplifies the process and automatically returns the forecasts on the original scale."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# We use the original time_series and let the model handle differencing with the 'd' parameter.\n",
    "# A common choice for (p,d,q) is (1,1,1). You may need to tune these parameters for your specific dataset.\n",
    "model_arima = ARIMA(time_series, order=(1, 1, 1)).fit()\n",
    "predictions_arima = model_arima.forecast(steps=12)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_series, label='Observed')\n",
    "plt.plot(predictions_arima, label='ARIMA Forecast')\n",
    "plt.title('ARIMA Forecast')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### SARIMA\n",
    "\n",
    "SARIMA (Seasonal ARIMA) is an extension of ARIMA that supports time series data with a seasonal component.\n",
    "\n",
    "A SARIMA model is characterized by 7 parameters: (p, d, q) x (P, D, Q, m).\n",
    "\n",
    "* **(p, d, q):** The non-seasonal parameters of the ARIMA model.\n",
    "* **(P, D, Q, m):** The seasonal parameters of the model, where 'm' is the number of time steps for a single seasonal period.\n",
    "\n",
    "Just like with ARIMA, we use the original time series here and let the model handle the differencing (both seasonal and non-seasonal) for us via the `d` and `D` parameters."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# A common choice for (p,d,q)(P,D,Q,m) is (1,1,1)(1,1,1,12).\n",
    "# You may need to tune these parameters for your specific dataset.\n",
    "model_sarima = SARIMAX(time_series, order=(1, 1, 1), seasonal_order=(1, 1, 1, 12)).fit()\n",
    "predictions_sarima = model_sarima.forecast(steps=12)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_series, label='Observed')\n",
    "plt.plot(predictions_sarima, label='SARIMA Forecast')\n",
    "plt.title('SARIMA Forecast')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Neural Network\n",
    "Long Short-Term Memory (LSTM) networks are a type of recurrent neural network (RNN) capable of learning long-term dependencies in sequence data. They are well suited for time series forecasting tasks because they can capture both short- and long-term temporal patterns.\n",
    "\n",
    "**Stationarity Requirement:** LSTM models do not strictly require the data to be stationary because they learn patterns directly from the raw sequences. However, it is recommended to scale the data and to remove strong trends or seasonality (for example, via differencing or decomposition) to improve convergence and predictive performance."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Prepare data for LSTM\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_series = scaler.fit_transform(time_series.values.reshape(-1, 1))\n",
    "\n",
    "# Create supervised learning sequences\n",
    "def create_sequences(data, window_size=12):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data[i:(i + window_size), 0])\n",
    "        y.append(data[i + window_size, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "window_size = 12\n",
    "X, y = create_sequences(scaled_series, window_size)\n",
    "train_size = len(X) - 12\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "model_lstm = Sequential([\n",
    "    LSTM(50, activation='tanh', input_shape=(window_size, 1)),\n",
    "    Dense(1)\n",
    "])\n",
    "model_lstm.compile(optimizer=Adam(learning_rate=0.01), loss='mse')\n",
    "\n",
    "history = model_lstm.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.1, verbose=0)\n",
    "\n",
    "predictions_lstm_scaled = model_lstm.predict(X_test)\n",
    "predictions_lstm = scaler.inverse_transform(predictions_lstm_scaled)\n",
    "lstm_index = time_series.index[-len(predictions_lstm):]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_series, label='Observed')\n",
    "plt.plot(lstm_index, predictions_lstm, label='LSTM Forecast')\n",
    "plt.title('LSTM Forecast')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Model Comparison"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Safe MAPE function\n",
    "def safe_mape(y_true, y_pred):\n",
    "    mask = y_true != 0\n",
    "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "\n",
    "# True values for comparison\n",
    "true_values = time_series[-12:]\n",
    "\n",
    "# Ensure predictions are properly aligned\n",
    "forecasts = {\n",
    "    'SES': predictions_ses[:12],\n",
    "    'Holt': predictions_holt[:12],\n",
    "    'Holt-Winters': predictions_hw[:12],\n",
    "    'ARIMA': predictions_arima[:12],\n",
    "    'SARIMA': predictions_sarima[:12],\n",
    "    'LSTM': pd.Series(predictions_lstm.flatten(), index=true_values.index)[:12]\n",
    "}\n",
    "\n",
    "# Compute metrics\n",
    "metrics = []\n",
    "for model_name, pred in forecasts.items():\n",
    "    mae = mean_absolute_error(true_values, pred)\n",
    "    rmse = np.sqrt(mean_squared_error(true_values, pred))\n",
    "    mape = safe_mape(true_values.values, pred.values)\n",
    "    metrics.append({'Model': model_name, 'MAE': mae, 'RMSE': rmse, 'MAPE': mape})\n",
    "\n",
    "# Create DataFrame\n",
    "metrics_df = pd.DataFrame(metrics).set_index('Model')\n",
    "print(\"Model Performance Comparison:\")\n",
    "print(metrics_df.round(2))\n",
    "\n",
    "# Plot metrics\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "metrics_df['MAE'].plot(kind='bar', ax=axes[0], title='MAE (Lower is Better)', color='skyblue')\n",
    "metrics_df['RMSE'].plot(kind='bar', ax=axes[1], title='RMSE (Lower is Better)', color='lightgreen')\n",
    "metrics_df['MAPE'].plot(kind='bar', ax=axes[2], title='MAPE % (Lower is Better)', color='salmon')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_ylabel('')\n",
    "    ax.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. Saving Predictions"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's see how to view and save our predictions to a CSV file."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"SES Predictions:\")\n",
    "print(predictions_ses)\n",
    "\n",
    "print(\"\\nHolt's Predictions:\")\n",
    "print(predictions_holt)\n",
    "\n",
    "print(\"\\nHolt-Winters Predictions:\")\n",
    "print(predictions_hw)\n",
    "\n",
    "print(\"\\nARIMA Predictions:\")\n",
    "print(predictions_arima)\n",
    "\n",
    "print(\"\\nSARIMA Predictions:\")\n",
    "print(predictions_sarima)\n",
    "\n",
    "print(\"\\nLSTM Predictions:\")\n",
    "# Convert predictions_lstm to Series with the same index as the last 12 true values\n",
    "lstm_series = pd.Series(predictions_lstm.flatten(), index=predictions_ses.index)\n",
    "print(lstm_series)\n",
    "\n",
    "# Save predictions to a CSV file\n",
    "predictions_df = pd.DataFrame({\n",
    "    'SES': predictions_ses,\n",
    "    'Holt': predictions_holt,\n",
    "    'Holt-Winters': predictions_hw,\n",
    "    'ARIMA': predictions_arima,\n",
    "    'SARIMA': predictions_sarima,\n",
    "    'LSTM': lstm_series\n",
    "})\n",
    "\n",
    "display(predictions_df)\n",
    "\n",
    "# predictions_df.to_csv('./data/SP500Index_predictions.csv')"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
