{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4gKSOfs5Hor9"
   },
   "source": "# Stationarity in Time Series Data"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "| Key              | Value                                                                                                                                                                                                                                                                                                            |\n",
    "|:-----------------|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Course Codes** | BBT 4206 and BFS 4102                                                                                                                                                                                                                                                                                            |\n",
    "| **Course Names** | BBT 4206: Business Intelligence II (Week 7-9 of 13)<br>BFS 4102: Advanced Business Data Analytics (Week 7-9 of 13)                                                                                                                                                                                               |\n",
    "| **Semester**     | August to November 2025                                                                                                                                                                                                                                                                                          |\n",
    "| **Lecturer**     | Allan Omondi                                                                                                                                                                                                                                                                                                     |\n",
    "| **Contact**      | aomondi@strathmore.edu                                                                                                                                                                                                                                                                                           |\n",
    "| **Note**         | The lecture contains both theory and practice.<br/>This notebook forms part of the practice.<br/>It is intended for educational purposes only.<br/>Recommended citation: [BibTex](https://raw.githubusercontent.com/course-files/TimeSeriesForecastingandNeuralNetworks/refs/heads/main/RecommendedCitation.bib) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0D8mz_y9HosC"
   },
   "source": [
    "### What is Stationarity?\n",
    "\n",
    "A time series is said to be **stationary** if its statistical properties such as mean, variance, and autocorrelation are at least approximately the same over time. Most time series models require the data to be stationary. If the time series is not stationary, we need to transform it to a stationary series before we can apply the models.\n",
    "\n",
    "A stationary time series has the following properties:\n",
    "\n",
    "- The mean should fluctuate around the same value over time\n",
    "- The variance should fluctuate around the same value over time\n",
    "- The covariance should not depend on time: `Cov[X(t), X(t+h)]` depends only on `h`, not on `t`. For example, the relationship between a data point and the one immediately following it (lag of 1) should be the same whether it is in the year 2000 or 2020.\n",
    "- The autocorrelation should fluctuate around the same value over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lJKnqDeAHosD"
   },
   "source": [
    "### Visual Indicators of Stationarity\n",
    "\n",
    "We can visually inspect a time series plot to get an idea of whether it is stationary or not. Here are some visual cues:\n",
    "\n",
    "- If there is a trend (upward or downward), the mean is not constant, and the series is not stationary.\n",
    "- If the spread of the data changes over time, the variance is not constant, and the series is not stationary.\n",
    "- There should be no seasonal patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6jvXG1C0HosD"
   },
   "source": [
    "Let's load our data and visualize it to check for stationarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 1: Import Libraries"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Purpose**: This chunk imports all the necessary libraries for data analysis, machine learning, and visualization.\n",
    "\n",
    "1. **For file and system operations [urllib3](https://urllib3.readthedocs.io/en/stable/)**\n",
    "    - `urllib.request` is used for opening and downloading data from URLs.\n",
    "    - `os` provides functions for interacting with the operating system, such as file and directory management.\n",
    "\n",
    "2. **For time seeries analysis - [pandas](https://pandas.pydata.org/pandas-docs/stable/getting_started/overview.html):**\n",
    "    - `pandas as pd`: For loading the dataset, creating and managing DataFrames, data manipulation and analysis using DataFrames\n",
    "    - `numpy as np`: For numerical operations, array manipulations, and mathematical functions\n",
    "    - `statsmodels.tsa.stattools import adfuller`: For performing the Augmented Dickey-Fuller (ADF) test to check for stationarity\n",
    "    - `statsmodels.tsa.seasonal import seasonal_decompose`: For decomposing the time series into its components (trend, seasonality, residual)\n",
    "    - `sklearn.linear_model import LinearRegression`: For fitting a linear regression model, useful for detrending the time series\n",
    "    - `re`: For regular expressions, useful for string manipulation and cleaning\n",
    "\n",
    "3. **For data visualization - [matplotlib](https://matplotlib.org/stable/gallery/index.html) and [seaborn](https://seaborn.pydata.org/examples/index.html)**\n",
    "    - `matplotlib.pyplot as plt`: For basic plotting functionality\n",
    "    - `mplfinance as mpf`: Specialized library for financial data visualization, particularly candlestick charts\n",
    "\n",
    "4. **For suppressing warnings - [warnings](https://docs.python.org/3/library/warnings.html)**\n",
    "    - `warnings`: Controls warning messages\n",
    "    - `warnings.filterwarnings('ignore')`: Suppresses warning messages for cleaner output\n",
    "    - Used to suppress warnings that may arise during the execution of the code. Even though it is not necessary for the code to run, it helps in keeping the output clean and focused on the results."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# For file and system operations\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "# For time series analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# For suppressing warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Ensures that matplotlib plots are displayed directly within the notebook,\n",
    "# right below the code cell that produces them. It makes visualizations appear\n",
    "# inline for easier viewing and analysis.\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 2: Load and Preprocess/Clean the Data"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load the Data"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dataset_path = './data/stockprice_cleaned.csv'\n",
    "\n",
    "if not os.path.exists(dataset_path):\n",
    "    print(\"❌ Please create the dataset first using the previous Jupyter Notebook.\")\n",
    "else:\n",
    "    print(\"✅ Dataset exists locally\")\n",
    "\n",
    "data = pd.read_csv(dataset_path, encoding='utf-8', nrows=200000)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Preprocess/Clean the Data"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1) Ensure datetime index and sorted\n",
    "\n",
    "# This line converts the `Date` column in the `data` DataFrame to datetime\n",
    "# objects. The `errors=\"coerce\"` argument means that any value that cannot\n",
    "# be parsed as a date will be replaced with `NaT` (Not a Time), which is\n",
    "# pandas' way of marking missing or invalid dates. This helps prevent errors\n",
    "# from invalid date formats and ensures the column is consistently typed.\n",
    "if \"Date\" in data.columns:\n",
    "    data[\"Date\"] = pd.to_datetime(data[\"Date\"], errors=\"coerce\")\n",
    "    data = data.set_index(\"Date\")\n",
    "\n",
    "data = data.sort_index()\n",
    "\n",
    "# 2) Normalize column names (trim, unify, and fix common naming)\n",
    "data.columns = [c.strip() for c in data.columns]\n",
    "rename_map = {\n",
    "    \"Close/Last\": \"Close\",\n",
    "    \"Adj Close\": \"Close\",\n",
    "    \"Adj. Close\": \"Close\",\n",
    "    \"Closing Price\": \"Close\",\n",
    "    \"Open Price\": \"Open\",\n",
    "    \"Opening Price\": \"Open\",\n",
    "    \"High Price\": \"High\",\n",
    "    \"Low Price\": \"Low\",\n",
    "    \"Trade Volume\": \"Volume\",\n",
    "    \"Volume (Shares)\": \"Volume\",\n",
    "    \"Total Volume\": \"Volume\",\n",
    "    \"High/Low\": \"High\",\n",
    "    \"Low/High\": \"Low\"\n",
    "}\n",
    "data = data.rename(columns=rename_map)\n",
    "\n",
    "# 3) Define a helper to strip non-numeric characters (keep digits, dot, minus)\n",
    "def to_numeric_str(s: str) -> str:\n",
    "    # Handle None/NaN safely\n",
    "    s = \"\" if s is None else str(s)\n",
    "    # Strip any characters except digits, decimal point, minus\n",
    "    return re.sub(r\"[^0-9.\\-]\", \"\", s)\n",
    "\n",
    "# 4) Coerce OHLC to float\n",
    "ohlc_cols = [c for c in [\"Open\", \"High\", \"Low\", \"Close\"] if c in data.columns]\n",
    "for c in ohlc_cols:\n",
    "    data[c] = pd.to_numeric(data[c].astype(str).map(to_numeric_str), errors=\"coerce\")\n",
    "\n",
    "# 5) Coerce Volume to numeric (basic version: strip non-numeric)\n",
    "if \"Volume\" in data.columns:\n",
    "    data[\"Volume\"] = pd.to_numeric(data[\"Volume\"].astype(str).map(to_numeric_str), errors=\"coerce\")\n",
    "\n",
    "# Optional: if your Volume has K/M/B suffixes (e.g., 12K, 3.5M, 1.2B) and you want correct scaling:\n",
    "def parse_volume(v):\n",
    "    v = str(v).strip()\n",
    "    if not v or v.lower() == \"nan\":\n",
    "        return float(\"nan\")\n",
    "    mult = 1\n",
    "    if v[-1] in \"KkMmBb\":\n",
    "        suffix = v[-1].upper()\n",
    "        v = to_numeric_str(v[:-1])\n",
    "        mult = {\"K\": 1_000, \"M\": 1_000_000, \"B\": 1_000_000_000}[suffix]\n",
    "    else:\n",
    "        v = to_numeric_str(v)\n",
    "    return float(v) * mult if v else float(\"nan\")\n",
    "if \"Volume\" in data.columns:\n",
    "    data[\"Volume\"] = data[\"Volume\"].map(parse_volume)\n",
    "\n",
    "# 6) Drop rows where any of OHLC are missing (mplfinance needs valid OHLC rows)\n",
    "if ohlc_cols:\n",
    "    data = data.dropna(subset=ohlc_cols)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Confirm Cleaned Data"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\n*1* The number of observations and variables\")\n",
    "display(data.shape)\n",
    "\n",
    "print(\"\\n*2* The data types:\")\n",
    "display(data.info())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\n*3* The summary of the numeric columns:\")\n",
    "display(data.describe())\n",
    "\n",
    "print(\"\\n*4* The whole dataset:\")\n",
    "display(data)\n",
    "\n",
    "print(\"\\n*5* The first 5 rows in the dataset:\")\n",
    "display(data.head())\n",
    "\n",
    "print(\"\\n*6* The last 5 rows in the dataset:\")\n",
    "display(data.tail())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 3: Plot the Data"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(25, 10))\n",
    "plt.plot(data[\"Close\"])\n",
    "plt.title(f\"Stock Price (Closing) Time Series\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Closing Price\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 4: Decompose the Time Series into its Components\n",
    "Decomposing a time series helps us understand its components: trend, seasonality, and residuals (or irregular component). This can provide insights into the underlying patterns in the data.\n",
    "We can use the `seasonal_decompose` function from `statsmodels` to decompose the time series. The decomposition can be either additive or multiplicative.\n",
    "- **Additive Decomposition:** The time series is expressed as the sum of its components: `Y(t) = Trend(t) + Seasonality(t) + Residual(t)`\n",
    "- **Multiplicative Decomposition:** The time series is expressed as the product of its components: `Y(t) = Trend(t) * Seasonality(t) * Residual(t)`. Multiplicative decomposition requires all values to be positive.\n",
    "- **Trend:** The long-term movement in the data.\n",
    "- **Seasonality:** The repeating short-term cycle in the data.\n",
    "- **Residual (Irregularity):** The random noise or irregular component in the data that cannot be explained by the trend or seasonality.\n",
    "- **Cycle:** A long-term oscillation in the data that is not necessarily seasonal. It can be thought of as a longer-term trend that fluctuates around a mean value. The cycle is often included in the residual if the decomposition is additive, as it captures long-term fluctuations that are not seasonal.\n",
    "\n",
    "**Period in Decomposition**\n",
    "- `period` is the number of observations per full seasonal cycle.\n",
    "- seasonal_decompose needs **at least two full cycles** in your data: `len(series) >= 2 × period`\n",
    "  - Example: If you set period = 252 or 365 but do not have at least ≈504 or ≈730 observations respectively, the decomposition will raise an error.\n",
    "- The ideal period depends on the cycle you want to capture and the sampling used when collecting the data. Common values for stock price include:\n",
    "  - Weekly trading cycle (business days): `period = 5`\n",
    "  - Monthly trading cycle: `period ≈ 21` (average trading days in a month)\n",
    "  - Quarterly trading cycle: `period ≈ 63` (21 trading days per month x 3 months)\n",
    "  - Annual trading cycle: `period ≈ 252` (trading days/year)\n",
    "  - Calendar daily data (inclusive of weekends and public holidays): `period = 7` (weekly), `period = 365` (annual)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# If data is already a Series, it uses it directly.\n",
    "# If data is a DataFrame, it selects the Close column and converts it to float64.\n",
    "ts = data if isinstance(data, pd.Series) else data[\"Close\"].astype('float64')\n",
    "\n",
    "# Ensure DateTimeIndex and set/keep frequency if possible\n",
    "if not isinstance(ts.index, pd.DatetimeIndex):\n",
    "    raise ValueError(\"Time series index must be a DateTimeIndex for seasonal decomposition.\")\n",
    "# Try to infer frequency if not present\n",
    "if ts.index.freq is None:\n",
    "    inferred = pd.infer_freq(ts.index)\n",
    "    if inferred is not None:\n",
    "        ts = ts.asfreq(inferred)\n",
    "\n",
    "# Decide model safely: multiplicative requires strictly positive values\n",
    "model_to_use = 'multiplicative' if (ts > 0).all() else 'additive'\n",
    "\n",
    "# Choose a sensible seasonal period based on frequency and desired cycle\n",
    "# Set which seasonal cycle you want to capture: 'weekly' (trading week) or 'annual' (trading year)\n",
    "seasonality_target = 'weekly'  # or 'annual'\n",
    "\n",
    "period = 63  # fallback default\n",
    "if ts.index.freq is not None:\n",
    "    freqstr = ts.index.freqstr.upper()\n",
    "    if 'B' in freqstr:  # Business-day frequency (weekdays only)\n",
    "        period = 5 if seasonality_target == 'weekly' else 252\n",
    "    elif 'M' in freqstr:  # Monthly\n",
    "        period = 12\n",
    "    elif 'W' in freqstr:  # Weekly\n",
    "        period = 52\n",
    "    elif 'Q' in freqstr:  # Quarterly\n",
    "        period = 4\n",
    "    elif 'D' in freqstr:  # Calendar daily (weekends included)\n",
    "        period = 7 if seasonality_target == 'weekly' else 365\n",
    "\n",
    "print(\"Detected frequency in the time series data is:\", ts.index.freq)\n",
    "\n",
    "# Decompose the time series\n",
    "decomposition = seasonal_decompose(ts, model=model_to_use, period=period)\n",
    "\n",
    "# Plot the components\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.subplot(411)\n",
    "plt.plot(decomposition.observed, label='Observed')\n",
    "plt.legend(loc='upper left')\n",
    "plt.subplot(412)\n",
    "plt.plot(decomposition.trend, label='Trend', color='purple')\n",
    "plt.legend(loc='upper left')\n",
    "plt.subplot(413)\n",
    "plt.plot(decomposition.seasonal, label='Seasonality (Quarterly)', color='green')\n",
    "plt.legend(loc='upper left')\n",
    "plt.subplot(414)\n",
    "plt.plot(decomposition.resid, label='Irregularity/Residual', color='red')\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 5: Statistical Tests of Stationarity\n",
    "\n",
    "Visual inspection can be subjective. Therefore, we use statistical tests to check for stationarity. One of the most commonly used tests is the **Augmented Dickey-Fuller (ADF) test**.\n",
    "\n",
    "The ADF test is a statistical test for the following hypothesis:\n",
    "\n",
    "* **Null Hypothesis (H0):** The time series is non-stationary.\n",
    "* **Alternative Hypothesis (H1):** The time series is stationary.\n",
    "\n",
    "We interpret the result of the ADF test using the p-value. If the p-value is less than a significance level (e.g., p<.05), we reject the null hypothesis and conclude that the time series is stationary."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def adf_test(series):\n",
    "    result = adfuller(series, autolag='AIC')\n",
    "    print(f'Augmented Dickey-Fuller (ADF) Statistic: {result[0]}')\n",
    "    print(f'p-value: {result[1]}')\n",
    "    # for key, value in result[4].items():\n",
    "    #     print('Critial Values:')\n",
    "    #     print(f'   {key}, {value}')\n",
    "\n",
    "adf_test(ts)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "If the p-value is greater than 0.05, we fail to reject the null hypothesis and conclude that the time series is non-stationary. In this case, we need to make the series stationary. A common way to do this is by **differencing** the series."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 6: Stationarizing Techniques (Data Transformation)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Differencing: Taking first differences `(Y(t) - Y(t-1))`"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# If the series is non-stationary, we can difference it\n",
    "time_series_differenced = ts.diff().dropna()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot the components\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.subplot(411)\n",
    "plt.plot(decomposition.observed, label='Observed')\n",
    "plt.legend(loc='upper left')\n",
    "plt.subplot(412)\n",
    "plt.plot(time_series_differenced, label='Differenced', color = 'purple')\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Perform ADF test on the differenced series\n",
    "adf_test(time_series_differenced)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Detrending: Removing trend components"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Prepare the time index as a feature for regression\n",
    "time_index = np.arange(len(ts)).reshape(-1, 1)\n",
    "\n",
    "# Fit linear regression (trend)\n",
    "lr = LinearRegression()\n",
    "lr.fit(time_index, ts.values)\n",
    "trend = lr.predict(time_index)\n",
    "\n",
    "# Detrend the series\n",
    "time_series_detrended = ts.values - trend"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot the components\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.subplot(411)\n",
    "plt.plot(decomposition.observed, label='Observed')\n",
    "plt.legend(loc='upper left')\n",
    "plt.subplot(412)\n",
    "plt.plot(ts.index, time_series_detrended, label='Detrended', color = 'green')\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Perform ADF test on the detrended series\n",
    "adf_test(time_series_detrended)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Log Transformation: For changing variance"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Apply log transformation (add a small constant if data contains zeros)\n",
    "time_series_log_transformed = np.log(ts + 1e-8)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot the components\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.subplot(411)\n",
    "plt.plot(decomposition.observed, label='Observed')\n",
    "plt.legend(loc='upper left')\n",
    "plt.subplot(412)\n",
    "plt.plot(ts.index, time_series_log_transformed, label='Log Transformed', color = 'brown')\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Perform ADF test on the detrended series\n",
    "adf_test(time_series_log_transformed)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Seasonal Differencing: For seasonal patterns"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Seasonal differencing (e.g., period=12 for monthly data)\n",
    "time_series_seasonal_differenced = ts.diff(63).dropna()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot the components\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.subplot(411)\n",
    "plt.plot(decomposition.observed, label='Observed')\n",
    "plt.legend(loc='upper left')\n",
    "plt.subplot(412)\n",
    "plt.plot(time_series_seasonal_differenced, label='Seasonal Differenced', color = 'orange')\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Perform ADF test on the detrended series\n",
    "adf_test(time_series_seasonal_differenced)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## In-Built Stationarizing Mechanism in Time Series Forecasting Algorithms\n",
    "1. **❌Exponential Smoothing (Simple, Double [Holt], and Triple [Holt-Winters])**\n",
    "    - Exponential Smoothing techniques do not require the series to be stationary.\n",
    "    - Instead, they explicitly model components such as trend and seasonality directly.\n",
    "    - They handle non-stationarity by design, rather than transforming the data to a stationary form.\n",
    "\n",
    "2. **✅ARIMA (AutoRegressive Integrated Moving Average)**\n",
    "    - ARIMA explicitly includes differencing (the \"I\" in ARIMA) as part of the model to make the series stationary.\n",
    "    - You specify the `d` parameter in `ARIMA(p, d, q)`, where:\n",
    "        - `d = 1` tells the model to difference the data once. This step transforms a non-stationary series into a stationary one internally.\n",
    "\n",
    "3. **✅SARIMA (Seasonal ARIMA)**\n",
    "    - SARIMA extends ARIMA with seasonal differencing.\n",
    "    - It uses two differencing parameters:\n",
    "        - `d` for non-seasonal differencing,\n",
    "        - `D` for seasonal differencing over a defined period m.\n",
    "    - Therefore, SARIMA also has built-in mechanisms to induce both stationarity and seasonal stationarity.\n",
    "\n",
    "4. **❌LSTM (Long Short-Term Memory Networks)**\n",
    "    - LSTM models do not have explicit stationarizing mechanisms.\n",
    "    - They learn directly from raw sequences, even if they are non-stationary.\n",
    "    - However, data preprocessing such as normalization and differencing often improves performance.\n",
    "    - LSTMs can model complex non-linear and non-stationary behavior, but they do not automatically make the data stationary."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
